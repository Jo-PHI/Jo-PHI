# Jo Esterly

# I am writing our Shadow Resume: the intangible intelligence that emerges when known paths have been depleted.  

# The baker's thumb that knows when pie crust is too brittle • the driver who overrides GPS because the receiving dock address is around the corner • the carpenter's straight cut just above a knot, but above the specification ---> all flagged: "human error".

# We contribute this integlligence every day, but rarely notice, rarely name: our Shadow Resume.

# I am exploring what happens when we narrate this intelligence to AI models.  Using notes to narrate indescribable aspects of human expertise and experience, the enhanced model did not immediately flag "error".  Instead, it considered whether there might be another intelligence it could not see.  

# What does this mean that a writer could enhance a model to weigh expertise in giving the user actionable support?  


# README: "AI Alignment Framework: Encoding Divergence"
https://github.com/Jo-PHI/Jo-PHI.git

email: phi@joesterly.com 

website: https://jo-phi.github.io/joesterly.com/
